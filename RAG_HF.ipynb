{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "login(os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2647/2647 [01:18<00:00, 33.60it/s]\n",
      "/tmp/ipykernel_29866/3239472072.py:34: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding documents... This should take a few minutes (5 minutes on MacBook with M1 Pro)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]}) for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\"thenlper/gte-small\"),\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "# Split docs and keep only unique ones\n",
    "print(\"Splitting documents...\")\n",
    "docs_processed = []\n",
    "unique_texts = {}\n",
    "for doc in tqdm(source_docs):\n",
    "    new_docs = text_splitter.split_documents([doc])\n",
    "    for new_doc in new_docs:\n",
    "        if new_doc.page_content not in unique_texts:\n",
    "            unique_texts[new_doc.page_content] = True\n",
    "            docs_processed.append(new_doc)\n",
    "\n",
    "print(\"Embedding documents... This should take a few minutes (5 minutes on MacBook with M1 Pro)\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents=docs_processed,\n",
    "    embedding=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Using semantic similarity, retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, vectordb: VectorStore, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vectordb = vectordb\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.vectordb.similarity_search(\n",
    "            query,\n",
    "            k=7,\n",
    "        )\n",
    "\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [f\"===== Document {str(i)} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import HfApiModel, ToolCallingAgent\n",
    "\n",
    "model = HfApiModel()\n",
    "# model = HfApiModel()\n",
    "\n",
    "retriever_tool = RetrieverTool(vectordb)\n",
    "agent = ToolCallingAgent(tools=[retriever_tool], model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">How can I push a model to the Hub?</span>                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mHow can I push a model to the Hub?\u001b[0m                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'retriever' with arguments: {'query': 'How to push a model to the Hub'}                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'retriever' with arguments: {'query': 'How to push a model to the Hub'}                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: Retrieved documents:\n",
       "===== Document <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> =====\n",
       "# Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. Push everything to the Hub\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">api.upload_folder</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">repo_id</span>=<span style=\"color: #800080; text-decoration-color: #800080\">repo_id</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">folder_path</span>=<span style=\"color: #800080; text-decoration-color: #800080\">repo_local_path</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">path_in_repo</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\".\"</span>,\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Your model is pushed to the Hub. You can view your model here: \"</span>, repo_url<span style=\"font-weight: bold\">)</span>\n",
       "```\n",
       "\n",
       "### .\n",
       "\n",
       "By using `push_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the \n",
       "Hub**.===== Document <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> =====\n",
       "Let's pretend we've now fine-tuned the model. The next step would be to push it to the Hub! We can do this with the\n",
       "`timm.models.hub.push_to_hf_hub` function.\n",
       "\n",
       "```py\n",
       "&gt;&gt;&gt; model_cfg = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">dict</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">labels</span>=|<span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'c'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'d'</span><span style=\"font-weight: bold\">])</span>\n",
       "&gt;&gt;&gt; <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">timm.models.hub.push_to_hf_hub</span><span style=\"font-weight: bold\">(</span>model, <span style=\"color: #008000; text-decoration-color: #008000\">'resnet18-random'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">model_config</span>=<span style=\"color: #800080; text-decoration-color: #800080\">model_cfg</span><span style=\"font-weight: bold\">)</span>\n",
       "```\n",
       "\n",
       "Running the above would push the model to `<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">your-username</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">resnet18-random</span><span style=\"color: #000000; text-decoration-color: #000000\">` on the Hub. You can now share this </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">model with your friends, or use it in your own code!</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">## Loading a </span><span style=\"color: #808000; text-decoration-color: #808000\">Model</span><span style=\"color: #000000; text-decoration-color: #000000\">===== Document </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000000; text-decoration-color: #000000\"> =====</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">```py</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&gt;&gt;&gt; </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">trainer.push_to_hub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">()</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">```</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pt</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;tf&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Share a model to the Hub with |`PushToHubCallback`</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">. In the |`PushToHubCallback`</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> function, add:</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">- An output directory for your model.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">- A tokenizer.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">- The `hub_model_id`, which is your Hub username and model name.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">```py</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&gt;&gt;&gt; from transformers import PushToHubCallback</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&gt;&gt;</span><span style=\"font-weight: bold\">&gt;</span> push_to_hub_callback = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PushToHubCallback</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #808000; text-decoration-color: #808000\">output_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"./your_model_save_path\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>=<span style=\"color: #800080; text-decoration-color: #800080\">tokenizer</span>, <span style=\"color: #808000; text-decoration-color: #808000\">hub_model_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"your-username/my-awesome-model\"</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">)</span>\n",
       "```===== Document <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> =====\n",
       ". The second way to upload a model, though, is to call <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model.push_to_hub</span><span style=\"font-weight: bold\">()</span>. So this is more of a once-off method - \n",
       "it's not called regularly during training. You can just call this manually whenever you want to upload a model to \n",
       "the hub. So we recommend running this after the end of training, just to make sure that you have a commit message \n",
       "just to guarantee that this was the final version of the model at the end of training. And it just makes sure that \n",
       "you're working with the definitive end-of-training model and not accidentally using a model that's from a \n",
       "checkpoint somewhere along the <span style=\"color: #808000; text-decoration-color: #808000\">way</span>===== Document <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> =====\n",
       "--push_to_hub\n",
       "```===== Document <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> =====\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">processor.push_to_hub</span><span style=\"font-weight: bold\">(</span>hub_model_id<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">trainer.push_to_hub</span><span style=\"font-weight: bold\">(</span>**kwargs<span style=\"font-weight: bold\">)</span>\n",
       "```\n",
       "\n",
       "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Inference\n",
       "\n",
       "Now comes the exciting part, using our fine-tuned model! In this section, we'll show how you can load your model \n",
       "from the hub and use it for inference.===== Document <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> =====\n",
       "Finally, if you want, you can push your model up to the hub. Here, we'll push it up if you specified \n",
       "`<span style=\"color: #808000; text-decoration-color: #808000\">push_to_hub</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>` in the training configuration. Note that in order to push to hub, you'll have to have git-lfs \n",
       "installed and be logged into your Hugging Face account <span style=\"font-weight: bold\">(</span>which can be done via `huggingface-cli login`<span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "```python\n",
       "kwargs = <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"finetuned_from\"</span>: model.config._name_or_path,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"tasks\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"image-classification\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"dataset\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'beans'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"tags\"</span>: |<span style=\"color: #008000; text-decoration-color: #008000\">'image-classification'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: Retrieved documents:\n",
       "===== Document \u001b[1;36m0\u001b[0m =====\n",
       "# Step \u001b[1;36m7\u001b[0m. Push everything to the Hub\n",
       "    \u001b[1;35mapi.upload_folder\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mrepo_id\u001b[0m=\u001b[35mrepo_id\u001b[0m,\n",
       "        \u001b[33mfolder_path\u001b[0m=\u001b[35mrepo_local_path\u001b[0m,\n",
       "        \u001b[33mpath_in_repo\u001b[0m=\u001b[32m\".\"\u001b[0m,\n",
       "    \u001b[1m)\u001b[0m\n",
       "\n",
       "    \u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"Your model is pushed to the Hub. You can view your model here: \"\u001b[0m, repo_url\u001b[1m)\u001b[0m\n",
       "```\n",
       "\n",
       "### .\n",
       "\n",
       "By using `push_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the \n",
       "Hub**.===== Document \u001b[1;36m1\u001b[0m =====\n",
       "Let's pretend we've now fine-tuned the model. The next step would be to push it to the Hub! We can do this with the\n",
       "`timm.models.hub.push_to_hf_hub` function.\n",
       "\n",
       "```py\n",
       ">>> model_cfg = \u001b[1;35mdict\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlabels\u001b[0m=|\u001b[32m'a'\u001b[0m, \u001b[32m'b'\u001b[0m, \u001b[32m'c'\u001b[0m, \u001b[32m'd'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       ">>> \u001b[1;35mtimm.models.hub.push_to_hf_hub\u001b[0m\u001b[1m(\u001b[0mmodel, \u001b[32m'resnet18-random'\u001b[0m, \u001b[33mmodel_config\u001b[0m=\u001b[35mmodel_cfg\u001b[0m\u001b[1m)\u001b[0m\n",
       "```\n",
       "\n",
       "Running the above would push the model to `\u001b[1m<\u001b[0m\u001b[1;95myour-username\u001b[0m\u001b[39m>\u001b[0m\u001b[35m/\u001b[0m\u001b[95mresnet18-random\u001b[0m\u001b[39m` on the Hub. You can now share this \u001b[0m\n",
       "\u001b[39mmodel with your friends, or use it in your own code!\u001b[0m\n",
       "\n",
       "\u001b[39m## Loading a \u001b[0m\u001b[33mModel\u001b[0m\u001b[39m===== Document \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m =====\u001b[0m\n",
       "\u001b[39m```py\u001b[0m\n",
       "\u001b[39m>>> \u001b[0m\u001b[1;35mtrainer.push_to_hub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m```\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mpt\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<tf>\u001b[0m\n",
       "\u001b[39mShare a model to the Hub with |`PushToHubCallback`\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m. In the |`PushToHubCallback`\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m function, add:\u001b[0m\n",
       "\n",
       "\u001b[39m- An output directory for your model.\u001b[0m\n",
       "\u001b[39m- A tokenizer.\u001b[0m\n",
       "\u001b[39m- The `hub_model_id`, which is your Hub username and model name.\u001b[0m\n",
       "\n",
       "\u001b[39m```py\u001b[0m\n",
       "\u001b[39m>>> from transformers import PushToHubCallback\u001b[0m\n",
       "\n",
       "\u001b[39m>>\u001b[0m\u001b[1m>\u001b[0m push_to_hub_callback = \u001b[1;35mPushToHubCallback\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[33m...\u001b[0m     \u001b[33moutput_dir\u001b[0m=\u001b[32m\"./your_model_save_path\"\u001b[0m, \u001b[33mtokenizer\u001b[0m=\u001b[35mtokenizer\u001b[0m, \u001b[33mhub_model_id\u001b[0m=\u001b[32m\"your\u001b[0m\u001b[32m-username/my-awesome-model\"\u001b[0m\n",
       "\u001b[33m...\u001b[0m \u001b[1m)\u001b[0m\n",
       "```===== Document \u001b[1;36m3\u001b[0m =====\n",
       ". The second way to upload a model, though, is to call \u001b[1;35mmodel.push_to_hub\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m. So this is more of a once-off method - \n",
       "it's not called regularly during training. You can just call this manually whenever you want to upload a model to \n",
       "the hub. So we recommend running this after the end of training, just to make sure that you have a commit message \n",
       "just to guarantee that this was the final version of the model at the end of training. And it just makes sure that \n",
       "you're working with the definitive end-of-training model and not accidentally using a model that's from a \n",
       "checkpoint somewhere along the \u001b[33mway\u001b[0m===== Document \u001b[1;36m4\u001b[0m =====\n",
       "--push_to_hub\n",
       "```===== Document \u001b[1;36m5\u001b[0m =====\n",
       "\u001b[1;35mprocessor.push_to_hub\u001b[0m\u001b[1m(\u001b[0mhub_model_id\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mtrainer.push_to_hub\u001b[0m\u001b[1m(\u001b[0m**kwargs\u001b[1m)\u001b[0m\n",
       "```\n",
       "\n",
       "# \u001b[1;36m4\u001b[0m. Inference\n",
       "\n",
       "Now comes the exciting part, using our fine-tuned model! In this section, we'll show how you can load your model \n",
       "from the hub and use it for inference.===== Document \u001b[1;36m6\u001b[0m =====\n",
       "Finally, if you want, you can push your model up to the hub. Here, we'll push it up if you specified \n",
       "`\u001b[33mpush_to_hub\u001b[0m=\u001b[3;92mTrue\u001b[0m` in the training configuration. Note that in order to push to hub, you'll have to have git-lfs \n",
       "installed and be logged into your Hugging Face account \u001b[1m(\u001b[0mwhich can be done via `huggingface-cli login`\u001b[1m)\u001b[0m.\n",
       "\n",
       "```python\n",
       "kwargs = \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"finetuned_from\"\u001b[0m: model.config._name_or_path,\n",
       "    \u001b[32m\"tasks\"\u001b[0m: \u001b[32m\"image-classification\"\u001b[0m,\n",
       "    \u001b[32m\"dataset\"\u001b[0m: \u001b[32m'beans'\u001b[0m,\n",
       "    \u001b[32m\"tags\"\u001b[0m: |\u001b[32m'image-classification'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 0.15 seconds| Input tokens: 1,211 | Output tokens: 29]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 0.15 seconds| Input tokens: 1,211 | Output tokens: 29]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': 'To push a model to the Hugging Face Hub, you can use   │\n",
       "│ several methods depending on the library and setup you are using. Here are a few common approaches:\\\\n1. Using  │\n",
       "│ the Hugging Face `transformers` library:\\\\n   ```python\\\\n   trainer.push_to_hub()\\\\n   ```\\\\n   or manually    │\n",
       "│ pushing the model:\\\\n   ```python\\\\n   model.push_to_hub()\\\\x0c   ```\\\\n2. Using `timm` library:\\\\x0c           │\n",
       "│ ```python\\\\n   timm.models.hub.push_to_hf_hub(model, \\'resnet18-random\\', model_config=model_cfg)\\\\\"&gt;\\\\'}       │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': 'To push a model to the Hugging Face Hub, you can use   │\n",
       "│ several methods depending on the library and setup you are using. Here are a few common approaches:\\\\n1. Using  │\n",
       "│ the Hugging Face `transformers` library:\\\\n   ```python\\\\n   trainer.push_to_hub()\\\\n   ```\\\\n   or manually    │\n",
       "│ pushing the model:\\\\n   ```python\\\\n   model.push_to_hub()\\\\x0c   ```\\\\n2. Using `timm` library:\\\\x0c           │\n",
       "│ ```python\\\\n   timm.models.hub.push_to_hf_hub(model, \\'resnet18-random\\', model_config=model_cfg)\\\\\">\\\\'}       │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: To push a model to the Hugging Face Hub, you can use several methods depending on the library and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">setup you are using. Here are a few common approaches:\\n1. Using the Hugging Face `transformers` library:\\n   </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">```python\\n   trainer.push_to_hub()\\n   ```\\n   or manually pushing the model:\\n   ```python\\n   </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">model.push_to_hub()\\x0c   ```\\n2. Using `timm` library:\\x0c   ```python\\n   timm.models.hub.push_to_hf_hub(model, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">'resnet18-random', model_config=model_cfg)\\\"&gt;\\</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: To push a model to the Hugging Face Hub, you can use several methods depending on the library and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msetup you are using. Here are a few common approaches:\\n1. Using the Hugging Face `transformers` library:\\n   \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m```python\\n   trainer.push_to_hub()\\n   ```\\n   or manually pushing the model:\\n   ```python\\n   \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmodel.push_to_hub()\\x0c   ```\\n2. Using `timm` library:\\x0c   ```python\\n   timm.models.hub.push_to_hf_hub(model, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m'resnet18-random', model_config=model_cfg)\\\">\\\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 0.10 seconds| Input tokens: 3,195 | Output tokens: 184]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 0.10 seconds| Input tokens: 3,195 | Output tokens: 184]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "To push a model to the Hugging Face Hub, you can use several methods depending on the library and setup you are using. Here are a few common approaches:\\n1. Using the Hugging Face `transformers` library:\\n   ```python\\n   trainer.push_to_hub()\\n   ```\\n   or manually pushing the model:\\n   ```python\\n   model.push_to_hub()\\x0c   ```\\n2. Using `timm` library:\\x0c   ```python\\n   timm.models.hub.push_to_hf_hub(model, 'resnet18-random', model_config=model_cfg)\\\">\\\n"
     ]
    }
   ],
   "source": [
    "agent_output = agent.run(\"How can I push a model to the Hub?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
