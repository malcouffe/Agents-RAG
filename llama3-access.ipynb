{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17326c1e8edc47cfb51ca45d1e013abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519c39e8e054409088c83a1be5bd2c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e4b2279923413490f7fb705ccf7b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "huggingface_doc.csv:   0%|          | 0.00/22.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d992a3b5406b44079697ee3226278b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caba39e9ed3443d58b9412e5aeddd7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676b8343dfc64292bc28edc661a8d661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1b6ca4118d4b53a1c49e0464f71c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce77b6ccb9c04e1d9078dfd40e1c3943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2647/2647 [01:34<00:00, 27.90it/s]\n",
      "/tmp/ipykernel_8622/3239472072.py:34: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding documents... This should take a few minutes (5 minutes on MacBook with M1 Pro)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39b230bfa3640d0aca60fc950d871c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c841d2aebf4361ad1dba484eb6f115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63d1f5fafcc4038996ccd916725b400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0520768265c420b835479c515df1f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f2e028d15f4723af292f169bbb87ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/66.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3a0e69f3c44d50a02b4bdbd782643d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]}) for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\"thenlper/gte-small\"),\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "# Split docs and keep only unique ones\n",
    "print(\"Splitting documents...\")\n",
    "docs_processed = []\n",
    "unique_texts = {}\n",
    "for doc in tqdm(source_docs):\n",
    "    new_docs = text_splitter.split_documents([doc])\n",
    "    for new_doc in new_docs:\n",
    "        if new_doc.page_content not in unique_texts:\n",
    "            unique_texts[new_doc.page_content] = True\n",
    "            docs_processed.append(new_doc)\n",
    "\n",
    "print(\"Embedding documents... This should take a few minutes (5 minutes on MacBook with M1 Pro)\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents=docs_processed,\n",
    "    embedding=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Using semantic similarity, retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, vectordb: VectorStore, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vectordb = vectordb\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.vectordb.similarity_search(\n",
    "            query,\n",
    "            k=7,\n",
    "        )\n",
    "\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [f\"===== Document {str(i)} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64497f7e29940c8b5c9e57bf5c2923a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfeccdc546042748ef06c83edf36daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/92.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b83fd13b34433c9e7aad9ff5ff9f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04c9313e4f8426da47d64607991e945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00019.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7598798dff3947e3ba181eba287558d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4da3ab9e4b45148b5f9659a77b6edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f15122d80a4686b24f6fd28305f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5629589e5efc40b2b659d1c44cc3e3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e95da15bb1b4cc7821b852155c6eb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60367c3179474de6a0cd87578ae977a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1759531cbd2e42a496aa52c48ac192ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381baa437f6a44d8a35124dd6ddb10f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a537541d81fd4ca68fe0c3eb3c37baed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2756f513c74580a21d0dd7f2af8910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from smolagents import HfApiModel, ToolCallingAgent\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# model = HfApiModel(\"mistralai/Mixtral-8x7B-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")\n",
    "\n",
    "retriever_tool = RetrieverTool(vectordb)\n",
    "agent = ToolCallingAgent(tools=[retriever_tool], model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">How can I push a model to the Hub?</span>                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - mistralai/Mixtral-8x7B-v0.1 ──────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mHow can I push a model to the Hub?\u001b[0m                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - mistralai/Mixtral-8x7B-v0.1 \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating tool call with model:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(Request ID: pu-6hW)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">403</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Forbidden: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">None</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Cannot access content at: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure your token has the correct permissions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The model mistralai/Mixtral-8x7B-v0.</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> is too large to be loaded automatically (93GB &gt; 10GB).</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating tool call with model:\u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: pu-6hW\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31m403\u001b[0m\u001b[1;31m Forbidden: \u001b[0m\u001b[1;3;31mNone\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mCannot access content at: \u001b[0m\n",
       "\u001b[1;4;31mhttps://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\u001b[0m\n",
       "\u001b[1;31mMake sure your token has the correct permissions.\u001b[0m\n",
       "\u001b[1;31mThe model mistralai/Mixtral-8x7B-v0.\u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m is too large to be loaded automatically \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m93GB > 10GB\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 0.27 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 0.27 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating tool call with model:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(Request ID: qDfSO9)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">403</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Forbidden: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">None</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Cannot access content at: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure your token has the correct permissions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The model mistralai/Mixtral-8x7B-v0.</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> is too large to be loaded automatically (93GB &gt; 10GB).</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating tool call with model:\u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: qDfSO9\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31m403\u001b[0m\u001b[1;31m Forbidden: \u001b[0m\u001b[1;3;31mNone\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mCannot access content at: \u001b[0m\n",
       "\u001b[1;4;31mhttps://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\u001b[0m\n",
       "\u001b[1;31mMake sure your token has the correct permissions.\u001b[0m\n",
       "\u001b[1;31mThe model mistralai/Mixtral-8x7B-v0.\u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m is too large to be loaded automatically \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m93GB > 10GB\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 0.18 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 0.18 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating tool call with model:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(Request ID: ONELkZ)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">403</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Forbidden: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">None</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Cannot access content at: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure your token has the correct permissions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The model mistralai/Mixtral-8x7B-v0.</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> is too large to be loaded automatically (93GB &gt; 10GB).</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating tool call with model:\u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: ONELkZ\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31m403\u001b[0m\u001b[1;31m Forbidden: \u001b[0m\u001b[1;3;31mNone\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mCannot access content at: \u001b[0m\n",
       "\u001b[1;4;31mhttps://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\u001b[0m\n",
       "\u001b[1;31mMake sure your token has the correct permissions.\u001b[0m\n",
       "\u001b[1;31mThe model mistralai/Mixtral-8x7B-v0.\u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m is too large to be loaded automatically \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m93GB > 10GB\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 0.12 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 0.12 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating tool call with model:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(Request ID: eGwEC3)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">403</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Forbidden: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">None</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Cannot access content at: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure your token has the correct permissions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The model mistralai/Mixtral-8x7B-v0.</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> is too large to be loaded automatically (93GB &gt; 10GB).</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating tool call with model:\u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: eGwEC3\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31m403\u001b[0m\u001b[1;31m Forbidden: \u001b[0m\u001b[1;3;31mNone\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mCannot access content at: \u001b[0m\n",
       "\u001b[1;4;31mhttps://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\u001b[0m\n",
       "\u001b[1;31mMake sure your token has the correct permissions.\u001b[0m\n",
       "\u001b[1;31mThe model mistralai/Mixtral-8x7B-v0.\u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m is too large to be loaded automatically \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m93GB > 10GB\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 0.17 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 0.17 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m4\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating tool call with model:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(Request ID: hFFEtd)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">403</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Forbidden: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">None</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Cannot access content at: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure your token has the correct permissions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The model mistralai/Mixtral-8x7B-v0.</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> is too large to be loaded automatically (93GB &gt; 10GB).</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating tool call with model:\u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: hFFEtd\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31m403\u001b[0m\u001b[1;31m Forbidden: \u001b[0m\u001b[1;3;31mNone\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mCannot access content at: \u001b[0m\n",
       "\u001b[1;4;31mhttps://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\u001b[0m\n",
       "\u001b[1;31mMake sure your token has the correct permissions.\u001b[0m\n",
       "\u001b[1;31mThe model mistralai/Mixtral-8x7B-v0.\u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m is too large to be loaded automatically \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m93GB > 10GB\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 4: Duration 0.11 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 4: Duration 0.11 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m5\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating tool call with model:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(Request ID: 19IG0z)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">403</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Forbidden: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">None</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Cannot access content at: </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure your token has the correct permissions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The model mistralai/Mixtral-8x7B-v0.</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> is too large to be loaded automatically (93GB &gt; 10GB).</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating tool call with model:\u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: 19IG0z\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31m403\u001b[0m\u001b[1;31m Forbidden: \u001b[0m\u001b[1;3;31mNone\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mCannot access content at: \u001b[0m\n",
       "\u001b[1;4;31mhttps://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\u001b[0m\n",
       "\u001b[1;31mMake sure your token has the correct permissions.\u001b[0m\n",
       "\u001b[1;31mThe model mistralai/Mixtral-8x7B-v0.\u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m is too large to be loaded automatically \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m93GB > 10GB\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 5: Duration 0.12 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 5: Duration 0.12 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Reached max steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mReached max steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Final answer: Error in generating final LLM output:\n",
       "(Request ID: -rG5O4)\n",
       "\n",
       "403 Forbidden: None.\n",
       "Cannot access content at: \n",
       "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\n",
       "Make sure your token has the correct permissions.\n",
       "The model mistralai/Mixtral-8x7B-v0.1 is too large to be loaded automatically (93GB &gt; 10GB).\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Final answer: Error in generating final LLM output:\n",
       "(Request ID: -rG5O4)\n",
       "\n",
       "403 Forbidden: None.\n",
       "Cannot access content at: \n",
       "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\n",
       "Make sure your token has the correct permissions.\n",
       "The model mistralai/Mixtral-8x7B-v0.1 is too large to be loaded automatically (93GB > 10GB).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 6: Duration 0.12 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 6: Duration 0.12 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "Error in generating final LLM output:\n",
      "(Request ID: -rG5O4)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1/v1/chat/completions.\n",
      "Make sure your token has the correct permissions.\n",
      "The model mistralai/Mixtral-8x7B-v0.1 is too large to be loaded automatically (93GB > 10GB).\n"
     ]
    }
   ],
   "source": [
    "agent_output = agent.run(\"How can I push a model to the Hub?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
